# 学习笔记 - 第1周

平时工作正经地使用 `Python` 开发程序的工作比较少，涉及到开发工作的主要是用 `bash` 实现的。  
编程需要多练，所以除了买别的教程学习之外，这次报名训练营也是想督促自己实际练练手。

## 爬虫

我觉得爬虫是一个很好的切入到 Python 编程的主题，它包含了 web 应用的后台部分，也是大数据项目的数据来源之一。  
如果能处理好大规模爬虫和破解反爬虫，则表示对`并发编程`和`前端技术`也有一定了解了。  

### 关于第三方包和模块

爬虫当中使用到的 `requests`、`BeautifulSoup`等，如果有时间我想我会阅读一下源码，其实主要目的是想搞清楚HTTP协议里的详细逻辑，以及如何实现一个自定义的标签元素查找器。

### Scrapy 框架

虽然没有深入研究过，但是看起来拥有一个不错的API server的思想。  
我觉得学习框架的实现比requests、 BS4等功能包的实现优先度更高。  
我认为在实际工程中抽象工作流、优雅地实现代码功能复用的能力是最重要的，框架在这方面会有综合地应用。  
举个例子，在实现自定义的Item类的时候，我注意到，在Item类中定义属性，初始化为scrapy.Field()，就可以让Item类的属性像字典一样进行赋值。  
scrapy.Fiele()本身是一个集成了字典类型的类，虽然没有详细地去查阅，不过这种让自定义类只能拥有定义过的属性的正确写法也是面向对象技术的基本技能之一，希望以后在使用框架的同时能更多地意识到哪里有值得借鉴，思考的地方，再自己去查一下在Python中的实现方法，依次来增加自己的综合编程能力。

## 作业

目前只做了第一个，爬取猫眼的前10个电影信息并保存为csv。  
遇到猫眼反爬虫需要人工滑动解锁这个暂时应该没有办法通过程序全自动处理，希望以后能学到相关技术手段。  
目前是手动解锁再把cookie写到程序里，当然这个写到文本里再载入也可以，不过本质上需要人肉解锁一次，所以意义不大。  
Tag的find_all()方法返回匹配条件的子Tag对象列表，我将它转换成生成器再用next()函数来迭代10次，以取到前10个电影。  
不知道BeautifulSoup本身有没有方法实现了类似的生成器，每次find完一次后记录当前的XML文档位置，下次find从当前位置开始查找，我看到有些方法是以...next()结尾的，看起来像是那样的功能，不过粗略试了下不行，就没有细看文档了。